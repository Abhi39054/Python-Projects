{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:00.906930Z","iopub.execute_input":"2025-06-26T16:12:00.907175Z","iopub.status.idle":"2025-06-26T16:12:02.538199Z","shell.execute_reply.started":"2025-06-26T16:12:00.907153Z","shell.execute_reply":"2025-06-26T16:12:02.537495Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/phishing-email-dataset/SpamAssasin.csv\n/kaggle/input/phishing-email-dataset/Nazario.csv\n/kaggle/input/phishing-email-dataset/Nigerian_Fraud.csv\n/kaggle/input/phishing-email-dataset/CEAS_08.csv\n/kaggle/input/phishing-email-dataset/Enron.csv\n/kaggle/input/phishing-email-dataset/Ling.csv\n/kaggle/input/phishing-email-dataset/phishing_email.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/phishing-email-dataset/phishing_email.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:07.669951Z","iopub.execute_input":"2025-06-26T16:12:07.670718Z","iopub.status.idle":"2025-06-26T16:12:10.500169Z","shell.execute_reply.started":"2025-06-26T16:12:07.670694Z","shell.execute_reply":"2025-06-26T16:12:10.499551Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:12.435548Z","iopub.execute_input":"2025-06-26T16:12:12.436176Z","iopub.status.idle":"2025-06-26T16:12:12.456627Z","shell.execute_reply.started":"2025-06-26T16:12:12.436152Z","shell.execute_reply":"2025-06-26T16:12:12.455922Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                       text_combined  label\n0  hpl nom may 25 2001 see attached file hplno 52...      0\n1  nom actual vols 24 th forwarded sabrae zajac h...      0\n2  enron actuals march 30 april 1 201 estimated a...      0\n3  hpl nom may 30 2001 see attached file hplno 53...      0\n4  hpl nom june 1 2001 see attached file hplno 60...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_combined</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hpl nom may 25 2001 see attached file hplno 52...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nom actual vols 24 th forwarded sabrae zajac h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>enron actuals march 30 april 1 201 estimated a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hpl nom may 30 2001 see attached file hplno 53...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hpl nom june 1 2001 see attached file hplno 60...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"\\nShape = \",df.shape)\nprint(\"\\nUnique Label = \",df[\"label\"].unique())\nprint(\"\\nNA Values = \\n\",df.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:19.984132Z","iopub.execute_input":"2025-06-26T16:12:19.984875Z","iopub.status.idle":"2025-06-26T16:12:20.010394Z","shell.execute_reply.started":"2025-06-26T16:12:19.984825Z","shell.execute_reply":"2025-06-26T16:12:20.009683Z"}},"outputs":[{"name":"stdout","text":"\nShape =  (82486, 2)\n\nUnique Label =  [0 1]\n\nNA Values = \n text_combined    0\nlabel            0\ndtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Train test split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df[\"text_combined\"], df[\"label\"], test_size=0.2, random_state=41)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:24.825753Z","iopub.execute_input":"2025-06-26T16:12:24.826463Z","iopub.status.idle":"2025-06-26T16:12:25.394370Z","shell.execute_reply.started":"2025-06-26T16:12:24.826438Z","shell.execute_reply":"2025-06-26T16:12:25.393771Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(\"X_train shape = \",X_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"X_test shape = \",X_train.shape)\nprint(\"y_test shape = \",X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:28.047899Z","iopub.execute_input":"2025-06-26T16:12:28.048372Z","iopub.status.idle":"2025-06-26T16:12:28.053212Z","shell.execute_reply.started":"2025-06-26T16:12:28.048348Z","shell.execute_reply":"2025-06-26T16:12:28.052417Z"}},"outputs":[{"name":"stdout","text":"X_train shape =  (65988,)\ny_train shape =  (65988,)\nX_test shape =  (65988,)\ny_test shape =  (65988,)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom transformers import BertTokenizer, BertModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:29.485119Z","iopub.execute_input":"2025-06-26T16:12:29.485684Z","iopub.status.idle":"2025-06-26T16:12:55.524538Z","shell.execute_reply.started":"2025-06-26T16:12:29.485658Z","shell.execute_reply":"2025-06-26T16:12:55.523946Z"}},"outputs":[{"name":"stderr","text":"2025-06-26 16:12:43.713117: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750954363.934219      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750954363.996889      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:12:58.390522Z","iopub.execute_input":"2025-06-26T16:12:58.391113Z","iopub.status.idle":"2025-06-26T16:13:00.157864Z","shell.execute_reply.started":"2025-06-26T16:12:58.391070Z","shell.execute_reply":"2025-06-26T16:13:00.157328Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d36436a97534fc499e85f889e968e64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30852c317fc245e5958844530ad061d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c58985ca5d4459495c35fe8167acbac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac77c20e0e943fb8e975afc8db82add"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def tokenize_function(texts, labels):\n    encoding = tokenizer(texts, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n    return encoding[\"input_ids\"], encoding[\"attention_mask\"], torch.tensor(labels, dtype=torch.float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:13:03.471926Z","iopub.execute_input":"2025-06-26T16:13:03.472222Z","iopub.status.idle":"2025-06-26T16:13:03.476478Z","shell.execute_reply.started":"2025-06-26T16:13:03.472201Z","shell.execute_reply":"2025-06-26T16:13:03.475415Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# tokenize_function([\"Hello, How are you!\"],[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:13:10.595135Z","iopub.execute_input":"2025-06-26T16:13:10.595845Z","iopub.status.idle":"2025-06-26T16:13:10.599039Z","shell.execute_reply.started":"2025-06-26T16:13:10.595821Z","shell.execute_reply":"2025-06-26T16:13:10.598355Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_input_ids, train_attention_mask, train_labels = tokenize_function(X_train.values.tolist(), y_train.values.tolist())\nval_input_ids, val_attention_mask, val_labels = tokenize_function(X_test.values.tolist(), y_test.values.tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:13:16.403724Z","iopub.execute_input":"2025-06-26T16:13:16.404628Z","iopub.status.idle":"2025-06-26T16:20:12.891780Z","shell.execute_reply.started":"2025-06-26T16:13:16.404594Z","shell.execute_reply":"2025-06-26T16:20:12.890743Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_mask, train_labels)\nval_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_mask, val_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:27:50.054618Z","iopub.execute_input":"2025-06-26T16:27:50.055418Z","iopub.status.idle":"2025-06-26T16:27:50.063622Z","shell.execute_reply.started":"2025-06-26T16:27:50.055387Z","shell.execute_reply":"2025-06-26T16:27:50.062937Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"batch_size=64\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:27:53.397032Z","iopub.execute_input":"2025-06-26T16:27:53.397340Z","iopub.status.idle":"2025-06-26T16:27:53.402254Z","shell.execute_reply.started":"2025-06-26T16:27:53.397319Z","shell.execute_reply":"2025-06-26T16:27:53.401444Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Load the pretrained model\n\nbert = BertModel.from_pretrained(\"bert-base-uncased\")\nbert.config.hidden_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:27:56.655090Z","iopub.execute_input":"2025-06-26T16:27:56.655358Z","iopub.status.idle":"2025-06-26T16:27:59.708475Z","shell.execute_reply.started":"2025-06-26T16:27:56.655337Z","shell.execute_reply":"2025-06-26T16:27:59.707744Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f0584c3ca34bc1b64457c8bd442f0c"}},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Define the model\nimport torch.nn as nn\n\nclass SentimentClassifier(nn.Module):\n\n    def __init__(self):\n\n        super(SentimentClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n        self.classifier = nn.Sequential(\n            nn.Linear(self.bert.config.hidden_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input_ids, attention_mask):\n\n        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        sentence_embedding = bert_output.last_hidden_state[:,0,:]\n        return self.classifier(sentence_embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:29:43.275672Z","iopub.execute_input":"2025-06-26T16:29:43.276193Z","iopub.status.idle":"2025-06-26T16:29:43.281565Z","shell.execute_reply.started":"2025-06-26T16:29:43.276172Z","shell.execute_reply":"2025-06-26T16:29:43.280816Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device : \",device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:29:43.962242Z","iopub.execute_input":"2025-06-26T16:29:43.962963Z","iopub.status.idle":"2025-06-26T16:29:43.967023Z","shell.execute_reply.started":"2025-06-26T16:29:43.962941Z","shell.execute_reply":"2025-06-26T16:29:43.966406Z"}},"outputs":[{"name":"stdout","text":"Device :  cuda\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model=SentimentClassifier().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.BCELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:38:57.258785Z","iopub.execute_input":"2025-06-26T16:38:57.259300Z","iopub.status.idle":"2025-06-26T16:38:57.773217Z","shell.execute_reply.started":"2025-06-26T16:38:57.259276Z","shell.execute_reply":"2025-06-26T16:38:57.772604Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"epochs = 2\n\nfor epoch in range(epochs):\n    model.train()\n    total_train_loss = 0.0\n    for batch, (input_ids, attention_mask, labels) in enumerate(train_dataloader):\n\n        optimizer.zero_grad()\n        outputs = model(input_ids.to(device), attention_mask.to(device)).squeeze()\n        loss = criterion(outputs, labels.to(device))\n        loss.backward()\n        optimizer.step()\n        total_train_loss += loss.item()\n\n    print(f\"Epoch: {epoch+1}/{epochs}, Loss: {total_train_loss / len(train_dataloader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:39:01.747992Z","iopub.execute_input":"2025-06-26T16:39:01.748902Z","iopub.status.idle":"2025-06-26T16:54:41.265224Z","shell.execute_reply.started":"2025-06-26T16:39:01.748872Z","shell.execute_reply":"2025-06-26T16:54:41.264306Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1/2, Loss: 0.2135836694158556\nEpoch: 2/2, Loss: 0.14778857860468733\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Test the model\n\nmodel.eval()\n\ntotal_val_loss  = 0\ncorrect_predictions  = 0\n\nwith torch.no_grad():\n\n    for input_ids, attention_mask, labels in val_dataloader:\n\n        outputs = model(input_ids.to(device), attention_mask.to(device)).squeeze()\n\n        loss = criterion(outputs, labels.to(device).view_as(outputs))\n\n        total_val_loss += loss.item()\n\n        preds = (outputs > 0.5).float()\n        # print(preds)\n        # print(torch.sum(preds.cpu() == labels.cpu()))\n        correct_predictions += torch.sum(preds.cpu() == labels.cpu())\n\navg_val_loss = total_val_loss / len(val_dataloader)\nval_accuracy = correct_predictions.double() / len(val_dataset)\nprint(f\"Validation Loss : {avg_val_loss:.4f}, Validation Accuracy : {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:59:44.077300Z","iopub.execute_input":"2025-06-26T16:59:44.077589Z","iopub.status.idle":"2025-06-26T17:01:39.598373Z","shell.execute_reply.started":"2025-06-26T16:59:44.077559Z","shell.execute_reply":"2025-06-26T17:01:39.597643Z"}},"outputs":[{"name":"stdout","text":"Validation Loss : 0.1045, Validation Accuracy : 0.9591\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"def predict(model, text, max_length=128):\n\n    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    # Tokenize input text\n    encoding = tokenizer(\n        text,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n\n    input_ids = encoding[\"input_ids\"]\n    attention_mask = encoding[\"attention_mask\"]\n\n    model.eval()\n    with torch.no_grad():\n        output = model(input_ids.to(device), attention_mask.to(device)).squeeze()\n        prediction = (output > 0.5).float().item()\n        return 'spam' if prediction == 1 else \"ham\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:08:42.946654Z","iopub.execute_input":"2025-06-26T17:08:42.947227Z","iopub.status.idle":"2025-06-26T17:08:42.951712Z","shell.execute_reply.started":"2025-06-26T17:08:42.947206Z","shell.execute_reply":"2025-06-26T17:08:42.951147Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"predict(model, \"Hello, You've won 1000$ free prize.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:08:55.268616Z","iopub.execute_input":"2025-06-26T17:08:55.269211Z","iopub.status.idle":"2025-06-26T17:08:55.438680Z","shell.execute_reply.started":"2025-06-26T17:08:55.269188Z","shell.execute_reply":"2025-06-26T17:08:55.437895Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'spam'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"predict(model, \"Hello, Please click on below link to avail your \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:09:23.468166Z","iopub.execute_input":"2025-06-26T17:09:23.468867Z","iopub.status.idle":"2025-06-26T17:09:23.664809Z","shell.execute_reply.started":"2025-06-26T17:09:23.468845Z","shell.execute_reply":"2025-06-26T17:09:23.664267Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'spam'"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"predict(model, \"Hello Sam - When can we expect the result?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T17:09:39.206849Z","iopub.execute_input":"2025-06-26T17:09:39.207421Z","iopub.status.idle":"2025-06-26T17:09:39.374023Z","shell.execute_reply.started":"2025-06-26T17:09:39.207399Z","shell.execute_reply":"2025-06-26T17:09:39.373410Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'ham'"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}